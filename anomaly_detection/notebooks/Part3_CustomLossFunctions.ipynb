{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e11df29-6653-44a8-b401-3bbc9ab4765c",
   "metadata": {},
   "source": [
    "## Part 3. Custom Loss Functions\n",
    "#### Alex Gagliano (gaglian2@mit.edu), IAIFI - January 8th, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dda5d93-ff21-4d4e-a637-55ccf6e834e3",
   "metadata": {},
   "source": [
    "In the previous section we looked into some way to extract meaningful features (both physical and non-physical) that describe our data instances, with the hope of manually identifying anomalies in the reduced-dimensionality space as as downstream task. Can we play games with our loss function to find better anomalies? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc2abc7-ba55-45d9-a726-6a26d1e1b877",
   "metadata": {},
   "source": [
    "The most straightforward way to do this is to modify our variational autoencoder from the previous section. To force the prediction of the kinds of anomalies that we're looking for, we can tack on a feed-forward layer to our VAE that squeezes the latent vector $z$ into a single number, which we'll call our anomaly score. Then, we can modify our loss function to take an additional term that guides the score toward anomaly scores from our labeled training set. Here's how that looks in practice: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "eb8579ba-7ca1-4f72-b234-e0ba219b5e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.nn import functional as F\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1c4a3e49-d83d-4a84-bd3b-79b0201d2459",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 99% the same network as before - the only thing that's changing is the few anomaly terms. \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size=7, hidden_size=400, num_layers=4, dropout=0.2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # x: tensor of shape (batch_size, seq_length, input_size)\n",
    "        # lengths: tensor of shape (batch_size), containing the lengths of each sequence in the batch\n",
    "\n",
    "        packed_x = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, hidden = self.gru(packed_x)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        return output, hidden\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size=7, hidden_size=400, output_size=4, num_layers=4, dropout=0.2\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, lengths=None):\n",
    "        if lengths is not None:\n",
    "            packed_x = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "            packed_output, hidden = self.gru(packed_x, hidden)\n",
    "            output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        else:\n",
    "            output, hidden = self.gru(x, hidden)\n",
    "        prediction = self.fc(output)\n",
    "        return prediction, hidden\n",
    "\n",
    "class anomaly_RNN_VAE(nn.Module):\n",
    "    \"\"\"RNN-VAE with added anomaly scorer!\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, input_size=7, hidden_size=400, latent_size=50, anomaly_latent_size=20, dropout=0.2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        input_size: int, batch_size x sequence_length x input_dim\n",
    "        hidden_size: int, output size \n",
    "        latent_size: int, latent z-layer size\n",
    "        num_gru_layer: int, number of layers\n",
    "        \"\"\"\n",
    "        super(anomaly_RNN_VAE, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "        # dimensions\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.latent_size = latent_size\n",
    "        self.anomaly_latent_size = anomaly_latent_size\n",
    "        self.num_layers = 4\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.enc = Encoder(input_size=input_size, hidden_size=hidden_size, num_layers=self.num_layers, dropout=self.dropout)\n",
    "        \n",
    "        self.dec = Decoder(\n",
    "            input_size=latent_size,\n",
    "            output_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            dropout=self.dropout,\n",
    "            num_layers=self.num_layers,\n",
    "        )\n",
    "\n",
    "        self.fc21 = nn.Linear(self.hidden_size, self.latent_size)\n",
    "        self.fc22 = nn.Linear(self.hidden_size, self.latent_size)\n",
    "        self.fc3 = nn.Linear(self.latent_size, self.hidden_size)\n",
    "\n",
    "        # THE ONLY NEW PIECE - a small feedforward network.\n",
    "        self.fc1_anomaly = nn.Linear(self.latent_size, self.anomaly_latent_size)\n",
    "        self.fc2_anomaly = nn.Linear(self.anomaly_latent_size, 1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            return mu + torch.randn(mu.shape).to(device)*torch.exp(0.5*logvar)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        batch_size, seq_len, feature_dim = x.shape\n",
    "    \n",
    "        enc_output, enc_hidden = self.enc(x, lengths)\n",
    "    \n",
    "        enc_h = enc_hidden[-1].to(device)  \n",
    "    \n",
    "        mu = self.fc21(enc_h)\n",
    "        logvar = self.fc22(enc_h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "\n",
    "        #use the feed-forward network to calculate a single anomaly score from the latent vector.\n",
    "        anomaly_score = self.fc2_anomaly(self.fc1_anomaly(z)).squeeze()\n",
    "        \n",
    "        h_ = self.fc3(z)\n",
    "        h_ = h_.unsqueeze(0)  \n",
    "        h_ = h_.repeat(self.dec.num_layers, 1, 1) \n",
    " \n",
    "        z = z.repeat(1, seq_len, 1)\n",
    "        z = z.view(batch_size, seq_len, self.latent_size).to(device)\n",
    "        \n",
    "        hidden = h_.contiguous()\n",
    "        x_hat, hidden = self.dec(z, hidden)\n",
    "    \n",
    "        return x_hat, mu, logvar, anomaly_score\n",
    "\n",
    "def anomaly_ELBO(x_hat, x, mu, logvar, anomaly_score, y):\n",
    "    MSE = torch.nn.MSELoss(reduction='sum')(x_hat, x)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    #loss term to guide the anomaly score\n",
    "    lam = 1.e5 #fine-tuned\n",
    "    anomaly_loss = lam*torch.nn.MSELoss(reduction='sum')(anomaly_score, y)\n",
    "    #print(\"anomaly loss is:\", anomaly_loss)\n",
    "    #print(\"MSE loss is:\", MSE)\n",
    "    return MSE + KLD + anomaly_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbd7ae1-af6b-4c63-80e2-440374c7bfe9",
   "metadata": {},
   "source": [
    "We'll caution that in practice, when adding in custom loss terms, it's common to modulate their strength with tuned coefficients so that your model doesn't only learn e.g., anomaly scoring without creating good light curve representations. But let's start there. Next, we need a training set. Here are my proposed anomaly scores for events in the training set, based on what I'm excited to discover in data from the Vera C. Rubin Observatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "276b6c9d-54f1-4e5b-a82e-342969329c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proposed dictionary mapping of anomaly scores, from above \n",
    "anomaly_dict = {90:0.1,  #SNIa\n",
    "                67:0.2,  #SNIa-91bg\n",
    "                52:0.2,  #SNIax\n",
    "                42:0.1,  #SNII\n",
    "                62:0.5,  #SNIbc\n",
    "                95:0.5, #SLSN-I\n",
    "                15:0.3,  #TDE\n",
    "                64:1.,    #KN\n",
    "                88:0.0,  #AGN\n",
    "                92:0.3,  #RRL\n",
    "                65:0.3,  #M-dwarf\n",
    "                16:0.0,  #EB\n",
    "                53:0.5,  #Mira\n",
    "                6:1.} #muLens-Single"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9d0f0d-a526-473f-bed2-bd90a0fc8a5a",
   "metadata": {},
   "source": [
    "As before, let's pre-process our datasets and train our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "cce0e452-227e-458b-9d61-7e9bd3691801",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_dataset = pd.read_csv(\"plasticc_train_lightcurves.csv\")\n",
    "labeled_dataset_detected = labeled_dataset[labeled_dataset['detected_bool'] == True]\n",
    "labeled_metadata =  pd.read_csv(\"plasticc_train_metadata.csv\")\n",
    "labeled_metadata['anomaly_score'] = labeled_metadata['true_target'].map(anomaly_dict)\n",
    "\n",
    "lcs_train = labeled_dataset_detected.sample(frac=0.8)\n",
    "lcs_val = labeled_dataset_detected[~labeled_dataset_detected['object_id'].isin(lcs_train['object_id'])]\n",
    "lcs_test = pd.read_csv(\"plasticc_test_lightcurves_01.csv\")\n",
    "\n",
    "dftest_metadata = pd.read_csv(\"./plasticc_test_metadata.csv\")\n",
    "lcs_train_wMetadata = lcs_train.merge(labeled_metadata)\n",
    "lcs_val_wMetadata = lcs_val.merge(labeled_metadata)\n",
    "\n",
    "lcs_test = pd.read_csv(\"plasticc_test_lightcurves_02.csv\")\n",
    "lcs_test_detected = lcs_test[lcs_test['detected_bool'] == True]\n",
    "lcs_test_wMetadata = lcs_test_detected.merge(dftest_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8189f36c-5027-4e94-849a-3ee23c61fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def preprocess_lcs(df, set='train'):\n",
    "    zpt = 27.5 #the zeropoint of the survey\n",
    "    df = df[df['flux'] > 0].copy(deep=True) #subset to only positive fluxes\n",
    "\n",
    "    df.loc[df['hostgal_photoz'] == 0, 'distmod'] = 28 #correponding to a redshift of ~0.001\n",
    "    df['absolute_mag'] = zpt - 2.5*np.log10(df['flux'].values) - df['distmod']\n",
    "    df['absolute_mag'] = -df['absolute_mag'] #flip the sign, so that magnitudes increase for brighter events\n",
    "    #this is an annoying aspect of astronomy...\n",
    "    df['mag_err'] = np.clip(1.0857 * np.abs(df['flux_err'].values/df['flux'].values), a_min=0, a_max=1.0)\n",
    "\n",
    "    # Get the central wavelengths of each filter in microns\n",
    "    # 0-6 correspond to Rubin's ugrizY\n",
    "    central_wvs = {0:3.751, 1:4.741, 2:6.172, 3:7.501, 4:8.679, 5:9.712}\n",
    "    oids = np.unique(df['object_id'])\n",
    "\n",
    "    data = []\n",
    "    target_class = []\n",
    "    oids_used = []\n",
    "    anomaly_score = []\n",
    "    for oid in oids: \n",
    "        lc = df[df['object_id'] == oid].copy(deep=True)\n",
    "        lc['wv'] = lc['passband'].map(central_wvs)\n",
    "        lc['phase'] = lc['mjd'] - np.nanmin(lc['mjd'])\n",
    "        lc = lc[lc['phase'] < 50].copy(deep=True)\n",
    "        \n",
    "        if len(lc) > 100:\n",
    "            lc = lc.sample(100)\n",
    "            \n",
    "        data.append(lc[['phase', 'absolute_mag', 'mag_err', 'wv', 'mwebv', 'hostgal_photoz', 'hostgal_photoz_err']].values)\n",
    "        target_class.append(lc['true_target'].values[0])\n",
    "        if set != 'test':\n",
    "            anomaly_score.append(lc['anomaly_score'].values[0])\n",
    "        else:\n",
    "            #since we don't have anomaly scores for the test set (yet) \n",
    "            anomaly_score.append(-1)\n",
    "    return target_class, data, anomaly_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "8909ba4c-6b30-490e-a47d-fbbf81c0ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this part might take a few minutes.\n",
    "train_labels, train_data, train_anomalyscore = preprocess_lcs(lcs_train_wMetadata, 'train')\n",
    "val_labels, val_data, val_anomalyscore = preprocess_lcs(lcs_val_wMetadata, 'val')\n",
    "test_labels, test_data, test_anomalyscore = preprocess_lcs(lcs_test_wMetadata, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b5d6e136-204a-4434-8230-898e0eeeeed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data, targets, anomaly_scores, lengths = zip(*batch)\n",
    "\n",
    "    # Convert sequences to tensors and pad them\n",
    "    sequences = [torch.tensor(d, dtype=torch.float32) for d in data]\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "\n",
    "    # Convert other data to tensors\n",
    "    anomaly_scores = torch.tensor(anomaly_scores, dtype=torch.float32)\n",
    "    targets = torch.tensor(targets, dtype=torch.float32)\n",
    "    lengths = torch.tensor(lengths)\n",
    "\n",
    "    return padded_sequences, targets, anomaly_scores, lengths\n",
    "    \n",
    "class LCDataset(Dataset):\n",
    "    def __init__(self, data, targets, anomaly_scores, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.anomaly_scores = anomaly_scores\n",
    "        self.lengths = [len(seq) for seq in data]\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        targets = self.targets[index]\n",
    "        anomaly_scores = self.anomaly_scores[index]\n",
    "        lengths = self.lengths[index]\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data, targets, anomaly_scores, lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8960a374-1112-4d3c-b05e-45fc9ce0b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = LCDataset(train_data, train_labels, train_anomalyscore)\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=32,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "val_ds = LCDataset(val_data, val_labels, val_anomalyscore)\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=32,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "\n",
    "test_ds = LCDataset(test_data, test_labels, test_anomalyscore)\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=32,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d4f8244b-8151-413e-a20d-eafe17677a6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training of anomaly scorer...\n",
      " Epoch 0 | Train: 11882.25 | Valid: 8596.05\n",
      " Epoch 1 | Train: 6663.39 | Valid: 8241.62\n",
      " Epoch 2 | Train: 6267.22 | Valid: 7717.61\n",
      " Epoch 3 | Train: 6135.77 | Valid: 7297.96\n",
      " Epoch 4 | Train: 6071.22 | Valid: 7718.83\n",
      " Epoch 5 | Train: 5963.96 | Valid: 7074.75\n",
      " Epoch 6 | Train: 5962.98 | Valid: 7586.00\n",
      " Epoch 7 | Train: 5892.65 | Valid: 6272.09\n",
      " Epoch 8 | Train: 5856.73 | Valid: 6699.25\n",
      " Epoch 9 | Train: 5793.68 | Valid: 6233.16\n"
     ]
    }
   ],
   "source": [
    "model = anomaly_RNN_VAE()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1.e-4)\n",
    "\n",
    "#iterate through 10 training epochs\n",
    "validation_losses = []\n",
    "training_losses = []\n",
    "\n",
    "nepochs = 10\n",
    "\n",
    "print(\"Beginning training of anomaly scorer...\")\n",
    "for epoch in range(0, nepochs):\n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x, y, anomaly_score, lengths in train_loader:\n",
    "        x = x.to(device)\n",
    "        x_hat, mu, logvar, predicted_score = model(x, lengths)\n",
    "        loss = anomaly_ELBO(x_hat, x, mu, logvar, anomaly_score, predicted_score)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # clip gradients to keep them at a reasonable size\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    # validate\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        for x, y, anomaly_score, lengths in val_loader:\n",
    "            x = x.to(device)\n",
    "            x_hat, mu, logvar, predicted_score = model(x, lengths)\n",
    "            valid_loss += anomaly_ELBO(x_hat, x, mu, logvar, anomaly_score, predicted_score)\n",
    "\n",
    "    validation_losses.append(valid_loss / len(val_loader.dataset))\n",
    "    training_losses.append(train_loss / len(train_loader.dataset))\n",
    "\n",
    "    print(f' Epoch {epoch} | Train: {train_loss / len(train_loader.dataset):.2f} | Valid: {valid_loss / len(val_loader.dataset):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168500bd-83f8-48b2-bbaf-8c559c88c668",
   "metadata": {},
   "source": [
    "We've only trained for 10 epochs, but let's see how well we do on the validation set anyway. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6a9a7b56-ecfd-41b5-9e08-f04af4f0ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_list = []\n",
    "anomaly_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    for x, y, anomaly_score, lengths in val_loader:\n",
    "        x = x.to(device)\n",
    "        x_hat, mu, logvar, predicted_score = model(x, lengths)\n",
    "        predicted_list.append(predicted_score)\n",
    "        anomaly_list.append(anomaly_score)\n",
    "\n",
    "anomaly_list = torch.cat(anomaly_list).cpu().numpy()\n",
    "predicted_list = torch.cat(predicted_list).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "bf004f93-d477-40d2-a6c4-bee73ed0bbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predicted_list, anomaly_list, 'o', mec='k')\n",
    "plt.xlabel(\"NN anomaly score\");\n",
    "plt.ylabel(\"Labeled anomaly score\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "5ffd25a1-22fb-4b0e-b43e-470a4c5d9a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n"
     ]
    }
   ],
   "source": [
    "# At least they're correlated! ...right? \n",
    "print(\"%.2f\"%np.corrcoef(predicted_list, anomaly_list)[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "45ac8132-4c63-4a93-b160-026f6f6bd976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the anomaly score of events in our test set? \n",
    "score_list = []\n",
    "y_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    for x, y, _, lengths in test_loader:\n",
    "        x = x.to(device)\n",
    "        x_hat, mu, logvar, score = model(x, lengths)        \n",
    "        score_list.append(score)\n",
    "        y_list.append(y)\n",
    "\n",
    "score_list = torch.cat(score_list).cpu().numpy()\n",
    "y_list = torch.cat(y_list).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b89116-4d1b-4fa7-9e14-ca65214c35c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a7c2a-de67-4eb3-9efc-1a9d8b72bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8b39e5-37de-4049-b7f4-82e3714a3847",
   "metadata": {},
   "source": [
    "Next, we can define a basic `anomaly threshold` as our cutoff, and compute our performance metrics: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "678ab37c-02dd-4cca-bdad-cb23133e3807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance metrics here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a691d0b-694d-4c63-af04-f65ebd0bb1c6",
   "metadata": {},
   "source": [
    "There should be a better way to incorporate labels from the training set. One technique that is increasingly employed in anomaly detection (and ML at large) is _contrastive learning_, in which the embedding space is guided to minimize the distance between similar events and maximize the distance between different events. A common loss is the _triplet loss_, where distances are considered between the _anchor_ (an event in question), a _negative_ (in this case, an event of a different class), and a _positive_ (an event of the same class). To make this work, we'll need a routine to split up a batch into these three categories: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d5f4c092-4ab5-440d-9d2f-a0824e124053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def select_triplets(batch, labels):\n",
    "    anchors, positives, negatives = [], [], []\n",
    "\n",
    "    for i, anchor in enumerate(batch):\n",
    "        anchor_label = labels[i]\n",
    "\n",
    "        #if we fail, it'll be because we have no matching events within a batch. Remember, this is a highly imbalanced traininng dataset!\n",
    "        try:\n",
    "            # Positive: different instance, same label\n",
    "            positive = random.choice([b for j, b in enumerate(batch) if labels[j] == anchor_label and j != i])\n",
    "    \n",
    "            # Negative: any instance with a different label\n",
    "            negative = random.choice([b for j, b in enumerate(batch) if labels[j] != anchor_label])\n",
    "        except IndexError:\n",
    "            continue\n",
    "\n",
    "        anchors.append(anchor)\n",
    "        positives.append(positive)\n",
    "        negatives.append(negative)\n",
    "\n",
    "    return torch.stack(anchors), torch.stack(positives), torch.stack(negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec612a6-70bc-418b-b9d5-38ab1f83e5bc",
   "metadata": {},
   "source": [
    "Next, we'll need a custom loss function that incorporates the calculation of the distance between these triplets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "cc48366c-e0e2-4963-947f-ff30ee399050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def contrastive_elbo(x_hat, x, mu, logvar, anchors, positives, negatives):\n",
    "    \n",
    "    MSE = torch.nn.MSELoss(reduction='sum')(x_hat, x)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    #loss to group similar phenomena\n",
    "    lam = 1. # custom weighting, unity for now\n",
    "    distance_positive = F.pairwise_distance(anchors, positives)\n",
    "    distance_negative = F.pairwise_distance(anchors, negatives)\n",
    "    margin = 0.01\n",
    "    contrastive_loss = F.relu(distance_positive - distance_negative + margin).mean()\n",
    "    \n",
    "    return MSE + KLD + lam*contrastive_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a6903-c8ad-4f0c-b4da-b0d54b88f23b",
   "metadata": {},
   "source": [
    "As before, we'll define our RNN VAE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2112f7c5-1dfd-47e0-b42d-9d3a6b7325fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_VAE(nn.Module):\n",
    "    \"\"\"Vanilla RNN-VAE\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, input_size=7, hidden_size=400, latent_size=50, dropout=0.2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        input_size: int, batch_size x sequence_length x input_dim\n",
    "        hidden_size: int, output size \n",
    "        latent_size: int, latent z-layer size\n",
    "        num_gru_layer: int, number of layers\n",
    "        \"\"\"\n",
    "        super(anomaly_RNN_VAE, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "        # dimensions\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.latent_size = latent_size\n",
    "        self.num_layers = 4\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.enc = Encoder(input_size=input_size, hidden_size=hidden_size, num_layers=self.num_layers, dropout=self.dropout)\n",
    "        \n",
    "        self.dec = Decoder(\n",
    "            input_size=latent_size,\n",
    "            output_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            dropout=self.dropout,\n",
    "            num_layers=self.num_layers,\n",
    "        )\n",
    "\n",
    "        self.fc21 = nn.Linear(self.hidden_size, self.latent_size)\n",
    "        self.fc22 = nn.Linear(self.hidden_size, self.latent_size)\n",
    "        self.fc3 = nn.Linear(self.latent_size, self.hidden_size)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            return mu + torch.randn(mu.shape).to(device)*torch.exp(0.5*logvar)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        batch_size, seq_len, feature_dim = x.shape\n",
    "    \n",
    "        enc_output, enc_hidden = self.enc(x, lengths)\n",
    "    \n",
    "        enc_h = enc_hidden[-1].to(device)  \n",
    "    \n",
    "        mu = self.fc21(enc_h)\n",
    "        logvar = self.fc22(enc_h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        \n",
    "        h_ = self.fc3(z)\n",
    "        h_ = h_.unsqueeze(0)  \n",
    "        h_ = h_.repeat(self.dec.num_layers, 1, 1) \n",
    " \n",
    "        z = z.repeat(1, seq_len, 1)\n",
    "        z = z.view(batch_size, seq_len, self.latent_size).to(device)\n",
    "        \n",
    "        hidden = h_.contiguous()\n",
    "        x_hat, hidden = self.dec(z, hidden)\n",
    "    \n",
    "        return x_hat, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8fb6530e-3c25-4485-97ab-92fbaa85f8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training of anomaly scorer...\n",
      " Epoch 0 | Train: 3874.82 | Valid: 412.09\n",
      " Epoch 1 | Train: 2467.26 | Valid: 327.14\n",
      " Epoch 2 | Train: 2379.92 | Valid: 294.86\n",
      " Epoch 3 | Train: 2289.37 | Valid: 271.02\n",
      " Epoch 4 | Train: 2253.62 | Valid: 258.26\n",
      " Epoch 5 | Train: 2215.75 | Valid: 245.76\n",
      " Epoch 6 | Train: 2107.27 | Valid: 212.33\n",
      " Epoch 7 | Train: 2056.79 | Valid: 193.78\n",
      " Epoch 8 | Train: 1989.62 | Valid: 187.34\n",
      " Epoch 9 | Train: 1997.77 | Valid: 174.44\n"
     ]
    }
   ],
   "source": [
    "model = RNN_VAE()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1.e-4)\n",
    "\n",
    "#iterate through 10 training epochs\n",
    "validation_losses = []\n",
    "training_losses = []\n",
    "\n",
    "nepochs = 10\n",
    "\n",
    "print(\"Beginning training of contrastive RNN-VAE...\")\n",
    "for epoch in range(0, nepochs):\n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x, y, _, lengths in train_loader:\n",
    "        x = x.to(device)\n",
    "        anchors, positives, negatives = select_triplets(x, y)\n",
    "        x_hat, mu, logvar = model(x, lengths)\n",
    "        loss = contrastive_elbo(x_hat, x, mu, logvar, anchors, positives, negatives)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # clip gradients to keep them at a reasonable size\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    # validate\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        for x, y, _, lengths in val_loader:\n",
    "            x = x.to(device)\n",
    "            anchors, positives, negatives = select_triplets(x, y)\n",
    "            x_hat, mu, logvar = model(x, lengths)\n",
    "            valid_loss += contrastive_elbo(x_hat, x, mu, logvar, anchors, positives, negatives)\n",
    "\n",
    "    validation_losses.append(valid_loss / len(val_loader.dataset))\n",
    "    training_losses.append(train_loss / len(train_loader.dataset))\n",
    "\n",
    "    print(f' Epoch {epoch} | Train: {train_loss / len(train_loader.dataset):.2f} | Valid: {valid_loss / len(val_loader.dataset):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "031ff228-634c-4e99-ad49-7a6d21625cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is our embedding space now more useful for pullling out anomalies? Let's find out, now with all light curves in the first test batch! \n",
    "mu_list = []\n",
    "y_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    for x, y, _, lengths in test_loader:\n",
    "        x = x.to(device)\n",
    "        x_hat, mu, logvar, _ = model(x, lengths)        \n",
    "        mu_list.append(mu)\n",
    "        y_list.append(y)\n",
    "\n",
    "mu_list = torch.cat(mu_list).cpu().numpy()\n",
    "y_list = torch.cat(y_list).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "3b4a237d-997b-43f7-8cfb-a7f4e95b2926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composition of labeled outliers: [('M-dwarf', 31), ('EB', 21), ('SNII', 19), ('RRL', 9), ('SN Ia', 6), ('SNIbc', 4), ('CaRT', 2), ('SLSN-I', 2), ('AGN', 2), ('Mira', 2), ('ILOT', 2)]\n",
      "Composition of labeled inliers: [('SN Ia', 53), ('SNII', 27), ('RRL', 10), ('SNIax', 3), ('EB', 3), ('SNIbc', 2), ('M-dwarf', 2)]\n"
     ]
    }
   ],
   "source": [
    "def getOutliers(y_list, outlier_scores, asc=False):\n",
    "    # get the names of the transients\n",
    "    y_names = np.vectorize(model_nums.get)(y_list)\n",
    "        \n",
    "    idx_sorted = np.argsort(outlier_scores)\n",
    "\n",
    "    #do larger numbers correspond to a higher anomaly score?\n",
    "    #if so, flip\n",
    "    if asc: \n",
    "        idx_sorted = idx_sorted[::-1]\n",
    "        \n",
    "    #get the top 100 outliers and the top 100 inliers\n",
    "    outliers = y_names[idx_sorted][0:100]\n",
    "    inliers = y_names[idx_sorted][-100:]\n",
    "    \n",
    "    c =  Counter(outliers)\n",
    "    c_ranked = [(i, c[i]) for i, count in c.most_common()]\n",
    "    print(\"Composition of labeled outliers:\",c_ranked)\n",
    "    \n",
    "    c =  Counter(inliers)\n",
    "    c_ranked = [(i, c[i]) for i, count in c.most_common()]\n",
    "    print(\"Composition of labeled inliers:\", c_ranked)\n",
    "    \n",
    "import hdbscan\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5, gen_min_span_tree=True)\n",
    "clusterer.fit(mu_list)\n",
    "outlier_scores = clusterer.outlier_scores_\n",
    "\n",
    "getOutliers(y_list, outlier_scores, asc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c797af50-47a5-4f03-9d8e-e94086c62a98",
   "metadata": {},
   "source": [
    "What's exciting is that, out of >338k total test events, we found 2/176 Intermediate-Luminosity Optical Transients (ILOTs) and 2/953 Calcium-Rich Transients (CaRTs) that were not present in the training set! This is also training over 10 epochs and not finding an anomaly score cutoff. Can you do better with a more sophisticated training routine? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
